{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-FeedForward.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwaNcYMBY3mTkmr1GHxHFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiseAboveAll/PYTORCH_Learning/blob/master/Pytorch_FeedForward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxA7pqV3WK0v",
        "colab_type": "text"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcCgrHsgtBO4",
        "colab_type": "text"
      },
      "source": [
        "- Type of neural network : Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXX_S81KWVvU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### **Forward Propogation**\n",
        "\n",
        "  -  Different neurons find different features from the input\n",
        "\n",
        "  -  Stack layers of neurons over layer\n",
        "\n",
        "  -  Same inputs can be attached to multiple different neurons, each calculating something different\n",
        "\n",
        "  -  Neurons of one layer can act as input to another layer, it increases depth and width of layer and network \n",
        "\n",
        "  -  A neuron : sigmoid(w.T . X + b)\n",
        "\n",
        "  -  Multiple Neurons : Consider when you have multiple neurons in a layer, let say from 1 to M, Zj=sigmoid(wj.T . X + bj) for j=1 to M . It can also be written more effeciently as in vector form : if Zj=sigmoid(Wj.T . X + bj) for j=1 to M then Z=sigmoid(W.T . X + b). Where :\n",
        "      \n",
        "      -  z is a matrices of size M (M x 1)\n",
        "\n",
        "      -  X is the vector of size D (Dx1) \n",
        "\n",
        "      -  W is the matrix of size D x M\n",
        "\n",
        "      -  b is a vector of size M ( Mx1 )\n",
        "\n",
        "      -  sigmoid() is an element wise multiplication\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZFHH7Rrx6kq",
        "colab_type": "text"
      },
      "source": [
        "### **Activation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6aCb0-sP_u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "- Sigmoid Activation:\n",
        "  \n",
        "  -  Makes neural network non linear\n",
        "\n",
        "  -  Issues with sigmoid activation function :\n",
        "\n",
        "      -  **Standardization** : We want our inputs to have mean of 0 and std at 1 and hence in same scale . Problem with sigmoid is that output is centered between 0 and 1, i.e at .5. The output of the sigmoid layer is input to the next layer . If the output is centered around 0.5 hence there is no uniformity , which is not good as next layer would also want to see the standardized input, hence we want both the input and the output of the layer both to be standardized.\n",
        "\n",
        "-  Hyperbolic Tangent(tanh) :\n",
        "\n",
        "    -  It is centered at 0 \n",
        "\n",
        "    -  It lies between -1 to 1 \n",
        "\n",
        "    -  tanh(a) = (exp(2a) - 1)/(exp(2a) + 1)\n",
        "\n",
        "    -  Issues with both **Sigmoid** & **Tanh** :\n",
        "\n",
        "        -  Vanishing Gradient : We use gradient descent to train the model. Hence we calculate the gradient of the cost with respect to parameters. The issue comes with deeper neural network, gradients have to propogate backwards throughout the networks starting from the end. Output is made of bunch of composite function, which are ove non-linear functions , hence when we take the gradient or derivative of composite function , we get chain rule, hence composite function becomes multiplication in the derivative. Derivative of sigmoid and tanh are near to 0 at flatter regions on both side of the axis. Only in the center it is non zero, maximum value of derivative is 0.25. When we multiply the smaller gradients consecutively , we get very small values, hence gradients become very small as we go further back in depth of neural network. Hence the gradients will vanish. \n",
        "\n",
        "\n",
        "-  ReLu : \n",
        "\n",
        "    -  Partially Differentiable\n",
        "\n",
        "    -  Values greater than 0 never have 0 gradient which makes training neural network lot more efficient. \n",
        "\n",
        "    -  ReLu does not have vanishing gradient as values less than equal 0 has already vanished. It is basically **Dead Neuron** . Dead Neurons are neurons which outputs always 0 because the weighted sum of its inputs are always less or equal 0. \n",
        "\n",
        "-  Leaky-Relu :\n",
        "\n",
        "    -  Has Slope < 1 for values less than 0 \n",
        "\n",
        "    -  Derivatives will always be positive \n",
        "\n",
        "-  ELU : \n",
        "\n",
        "    -  Higher speed of convergence\n",
        "\n",
        "    -  Higher accuracy\n",
        "\n",
        "    -  Allows outputs to be negative which goes back to the idea that mean of the values are close to 0 \n",
        "\n",
        "-  Softplus:\n",
        "\n",
        "    -  Taking log of the exponent, looks linear when the input is reasonably large. \n",
        "\n",
        "    -  For softplus and Relu minimum value is around 0 and maximum value is infinity , hence they are not centered around 0. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6E-L2-RKPLr",
        "colab_type": "text"
      },
      "source": [
        "**Something to try in activation function : BRU ( Bionodal Root Unit ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF2GIPSWk1J8",
        "colab_type": "text"
      },
      "source": [
        "Code for fully Connected layer block : Sequential :\n",
        "\n",
        "nn.Sequential(\n",
        "\n",
        "  nn.Linear(D,M),\n",
        "\n",
        "  nn.ReLU(),\n",
        "\n",
        "  nn.Linear(M,K),\n",
        "\n",
        "  nn.Softmax()\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z2T5U1Kn5W-",
        "colab_type": "text"
      },
      "source": [
        "**Do not Use the above code**\n",
        "\n",
        "Because pytorch combines the softmax function with the cross entropy loss (nn.CrossEntropyLoss) \n",
        "\n",
        "Code for multiclass Logistic Regression:\n",
        "\n",
        "model=nn.Linear(D,K)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "**pytorch does have standalone categorical loss called NLL Loss*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8lVF2VSpoVB",
        "colab_type": "text"
      },
      "source": [
        "### How to Represent Images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XCMF0YEpwnU",
        "colab_type": "text"
      },
      "source": [
        "**How Images are stored in Computer?**\n",
        "\n",
        "-  Images have two properties :\n",
        "\n",
        "    -  Height\n",
        "\n",
        "    -  Width\n",
        "\n",
        "-  It can be stored in form of **Matrix**, in an image matrix you store the color in form of pixel values. Colors comes in different channels like greyscale , RGB , etc. For eg : RGB, it is a set of 3 numbers , hence the matrix will have third dimension apart from height & width , it will be number of channels , i.e in case of RGB image , it is 3 , Hence it is an tensor of size (H,W,C). \n",
        "\n",
        "- **Quantization** : Physically color is light , measured by light intensity, hence it is continuous and has infinite possible values. But computers do not have infinite precision, hence in computers we have given each value as of 8 bits , i.e 2^8 = 256 possible values (0,1,2,....,255). Hence for 3 channels we have 2^8 * 2^8 * 2^8 = 16.8 million possible colors. Using this we can check how much space will an image consume. For example you hve 500 x 500 image , number of bits required = <code>500*500*3*8 = 6 million bits</code>. \n",
        "\n",
        "For images which are greyscale images, image can be either black or white or in between, it is a 2-D array(h,w), 0 represents **Black** & 255 represents **White**.\n",
        "\n",
        "**Image As Inputs**\n",
        "\n",
        "-  We do not use 8-bit valued image, neural network do not like a large scale values. Hence we scale images to have values between 0 and 1. 0 represents Black and 1 represent White in greyscale.  These are not standardized values as they are not centered around 0.  For images these values are convenient as these values can be represented as probabilities. \n",
        "\n",
        "<code>**Exception** VGG images are centered around 0 but the range is still 256.</code>\n",
        "\n",
        "**Images as inputs to neural network**\n",
        "\n",
        "-  Neural network expects input X to be of shape NxD, where <code> N is the number of samples</code> & <code> D is the number of Features</code>. An image can not have D features, it is 3-D object. Hence to represent the data set of images we would need to have a 4-D object of shape (N x H x W x C), where N is number of samples , H is height , W is width, C is number of channels. But when we are dealing with Fully Connected Dense Networks for images , we flatten the images by multiplying Height & Width hence shape is <code> (N , H*W*C) </code> . To do so we use <code> .view() </code> or <code> .reshape() </code> function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHblKgkIxz1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqGnJEJ-pvY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjHv3Sw1KNy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgIxwE1eV_4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}